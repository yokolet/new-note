---
layout: post
title: LRU Cache
algo_menubar: algo_menu
hero_height: is-small
tags:
- Medium
- Design
- Hash Table
date: 2022-09-09 23:09 +0900
---
## Introduction
This is well-known LRU (least recently used) cache problem.
A Class skeleton is provided.
We should implement initializer and methods.

The solution here uses Python's OrderedDict, which guarantees the order of
keys in first come basis.

## Problem Description
> Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.
>
> Implement the LRUCache class:
> - `LRUCache(int capacity)` Initialize the LRU cache with positive size capacity.
> - `int get(int key)` Return the value of the key if the key exists, otherwise return -1.
> - `void put(int key, int value)` Update the value of the key if the key exists.
>    Otherwise, add the key-value pair to the cache.
>    If the number of keys exceeds the capacity from this operation, evict the least recently used key.
> - The functions get and put must each run in `O(1)` average time complexity.
>
> Constraints:
> - `1 <= capacity <= 3000`
> - `0 <= key <= 10**4`
> - `0 <= value <= 10**5`
> - At most `2 * 10**5` calls will be made to get and put.
>
> [https://leetcode.com/problems/lru-cache/](https://leetcode.com/problems/lru-cache/)

## Examples
```
Example 1:
Input
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]
Output
[null, null, null, 1, null, -1, null, -1, 3, 4]

Explanation
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // cache is {1=1}
lRUCache.put(2, 2); // cache is {1=1, 2=2}
lRUCache.get(1);    // return 1
lRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is {1=1, 3=3}
lRUCache.get(2);    // returns -1 (not found)
lRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}
lRUCache.get(1);    // return -1 (not found)
lRUCache.get(3);    // return 3
lRUCache.get(4);    // return 4
```

## Analysis
The cache size and key order are what we should maintain.
The solution here uses Python's OrderedDict to maintain the order.
Everytime the key is referenced, that key moved to the end for both `get/put` method.
When the cache size grows up to the specified capacity,
The least recently used key is deleted.

## Solution
```python
class LRUCache:

    def __init__(self, capacity: int):
        self.cache = collections.OrderedDict()
        self.capacity = capacity

    def get(self, key: int) -> int:
        if key in self.cache:
            self.cache.move_to_end(key)
            return self.cache[key]
        else:
            return -1

    def put(self, key: int, value: int) -> None:
        if key not in self.cache and len(self.cache) == self.capacity:
            self.cache.popitem(last=False)
        self.cache[key] = value
        self.cache.move_to_end(key)
```

## Complexities
- Time: `O(1)`
- Space: `O(n)` -- n is a capacity
